{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fanmin/mambaforge/envs/acts_gpu_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from train import build_vocab_embedding, build_model\n",
    "from argparse import ArgumentParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique token len 37211\n"
     ]
    }
   ],
   "source": [
    "# init glove\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\n",
    "        \"--encoder\",\n",
    "        default=\"avg\",\n",
    "        choices=[\"avg\", \"lstm\", \"bi-lstm\", \"bi-lstm-max-pool\"],\n",
    "        type=str)\n",
    "parser.add_argument(\"--checkpt\", type=str)\n",
    "glove_vocab, pretrained_embeddings, _, _, _ = build_vocab_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "CHECK_PT = '/home/fanmin/atcs-lstm/models/avg-epoch=19-val_loss=0.66-val_accuracy=0.72.ckpt' # replace me\n",
    "args = parser.parse_args(['--encoder', 'avg', '--checkpt', CHECK_PT])\n",
    "model_avg = build_model(args, pretrained_embeddings)\n",
    "\n",
    "CHECK_PT = '/home/fanmin/atcs-lstm/models/lstm-epoch=4-val_loss=0.50-val_accuracy=0.80.ckpt' # replace me\n",
    "args = parser.parse_args(['--encoder', 'lstm', '--checkpt', CHECK_PT])\n",
    "model_lstm = build_model(args, pretrained_embeddings)\n",
    "\n",
    "CHECK_PT = '/home/fanmin/atcs-lstm/models/bi-lstm-epoch=4-val_loss=0.50-val_accuracy=0.80.ckpt' # replace me\n",
    "args = parser.parse_args(['--encoder', 'bi-lstm', '--checkpt', CHECK_PT])\n",
    "model_bilstm = build_model(args, pretrained_embeddings)\n",
    "\n",
    "CHECK_PT = '/home/fanmin/atcs-lstm/models/bi-lstm-max-pool-epoch=8-val_loss=0.42-val_accuracy=0.84.ckpt' # replace me\n",
    "args = parser.parse_args(['--encoder', 'bi-lstm-max-pool', '--checkpt', CHECK_PT])\n",
    "model_bilstm_max = build_model(args, pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "def eval(model, p, h):\n",
    "    p_ind = glove_vocab(word_tokenize(p))\n",
    "    h_tk = glove_vocab(word_tokenize(h))\n",
    "    p_text = torch.tensor([len(p_ind)])\n",
    "    h_text = torch.tensor([len(h_tk)])\n",
    "    prep = model(torch.tensor([p_ind]), p_text, torch.tensor([p_ind]), h_text)\n",
    "    print(f'{p},{h} has predict of {prep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two men sitting in the sun .,nobody is sitting in the shade . has predict of tensor([[ 0.4113, -0.7574,  0.3910]], grad_fn=<AddmmBackward0>)\n",
      "two men sitting in the sun .,nobody is sitting in the shade . has predict of tensor([[ 2.4773, -1.0979, -1.4170]], grad_fn=<AddmmBackward0>)\n",
      "two men sitting in the sun .,nobody is sitting in the shade . has predict of tensor([[ 3.2840, -0.8510, -2.2894]], grad_fn=<AddmmBackward0>)\n",
      "two men sitting in the sun .,nobody is sitting in the shade . has predict of tensor([[ 2.6835, -0.9080, -1.7141]], grad_fn=<AddmmBackward0>)\n",
      "a man is walking a dog .,no cat is outside . has predict of tensor([[ 6.4695, -2.2916, -3.9968]], grad_fn=<AddmmBackward0>)\n",
      "a man is walking a dog .,no cat is outside . has predict of tensor([[ 2.1044,  0.0434, -2.1469]], grad_fn=<AddmmBackward0>)\n",
      "a man is walking a dog .,no cat is outside . has predict of tensor([[ 1.7867,  0.4956, -2.2483]], grad_fn=<AddmmBackward0>)\n",
      "a man is walking a dog .,no cat is outside . has predict of tensor([[ 2.3490, -0.7016, -1.5854]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Evluate\n",
    "p = \"two men sitting in the sun .\"\n",
    "h = \"nobody is sitting in the shade .\"\n",
    "eval(model_avg, p, h)\n",
    "eval(model_lstm, p, h)\n",
    "eval(model_bilstm, p, h)\n",
    "eval(model_bilstm_max, p, h)\n",
    "\n",
    "\n",
    "p2 = \"a man is walking a dog .\"\n",
    "h2 = \"no cat is outside .\"\n",
    "eval(model_avg, p2, h2)\n",
    "eval(model_lstm, p2, h2)\n",
    "eval(model_bilstm, p2, h2)\n",
    "eval(model_bilstm_max, p2, h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking a the result, the predicted label for all the models on p and p2 are first label. \n",
    "The NLI labels are contradiction, neutral and entailment. Hence all trained models predict contradiction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acts_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
